{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR inputs & Corresponding outputs\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T\n",
    "Y_train = np.array([0, 1, 1, 0])\n",
    "\n",
    "plt.scatter(X_train.T[Y_train==1][:, 0], X_train.T[Y_train==1][:, 1], color='b', edgecolor='k', label='label : 1')\n",
    "plt.scatter(X_train.T[Y_train==0][:, 0], X_train.T[Y_train==0][:, 1], color='r', edgecolor='k', label='label : 0')\n",
    "plt.grid(True)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    # Your Code ...\n",
    "    \n",
    "    # Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReLU 함수정의\n",
    "def ReLU(z):\n",
    "    # Your Code ...\n",
    " \n",
    "    # Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = np.linspace(-6, 6, 500)\n",
    "plt.plot(x_range, ReLU(x_range))\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    \"\"\"   \n",
    "    Returns:\n",
    "    n_x -- the size of the input layer\n",
    "    n_h -- the size of the hidden layer\n",
    "    n_y -- the size of the output layer\n",
    "    \"\"\"\n",
    "    # You Code ...\n",
    " \n",
    " \n",
    " \n",
    "    # You Code ...\n",
    "    return (n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 임의의 데이터 ...\n",
    "X = np.array([[-0.00416758, -0.00056267],\n",
    "              [-0.02136196,  0.01640271],\n",
    "              [-0.01793436, -0.00841747],\n",
    "              [ 0.00502881, -0.01245288]]).T\n",
    "\n",
    "# 1차원 데이터가 네 개\n",
    "Y = np.array([[1.0],\n",
    "              [0.0],\n",
    "              [0.0],\n",
    "              [1.0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code ...\n",
    " \n",
    "# Your Code ...\n",
    "print(n_x, n_h, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x, n_h, n_y, init_scale_factor=1.0):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    params -- python dictionary containing your parameters:\n",
    "                    W1 -- weight matrix of shape (n_h, n_x)\n",
    "                    b1 -- bias vector of shape (n_h, 1)\n",
    "                    W2 -- weight matrix of shape (n_y, n_h)\n",
    "                    b2 -- bias vector of shape (n_y, 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    np.random.seed(2019)\n",
    "    \n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "\n",
    "# Your Code ...\n",
    " \n",
    "# Your Code ...\n",
    "\n",
    "print(\"W1 = \" + str(parameters[\"W1\"]))\n",
    "print(\"b1 = \" + str(parameters[\"b1\"]))\n",
    "print(\"W2 = \" + str(parameters[\"W2\"]))\n",
    "print(\"b2 = \" + str(parameters[\"b2\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X, parameters):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    A2 -- The sigmoid output of the second activation\n",
    "    cache -- a dictionary containing \"Z1\", \"A1\", \"Z2\" and \"A2\"\n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    \n",
    "    # Implement Forward Propagation to calculate A2(=Yhat) (probabilities)\n",
    "    # A = Activation( W^t * X + bias )\n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "    \n",
    "    return A2, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "\n",
    "# Your Code ...\n",
    " \n",
    "# Your Code ...\n",
    "\n",
    "# Note: we use the mean here just to make sure that your output matches ours. \n",
    "print(np.mean(cache['Z1']), np.mean(cache['A1']), np.mean(cache['Z2']), np.mean(cache['A2']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ J = - \\frac{1}{m} \\sum\\limits_{i = 0}^{m} \\Big\\{ y^{(i)}\\log\\left(\\hat{y}^{(i)}\\right) + (1-y^{(i)})\\log\\left(1- \\hat{y}^{(i)}\\right) \\Big\\} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A2, Y, parameters):\n",
    "    \"\"\"\n",
    "    Returns: \n",
    "    cost -- cross-entropy cost given equation (13)\n",
    "    \"\"\"\n",
    "    \n",
    "    m = Y.shape[1] # number of example\n",
    "    \n",
    "    # Compute the cross-entropy cost\n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    cost = np.squeeze(cost) # 파이썬 숫자로 출력하기 위함 (E.g., turns [[17]] into 17)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "# A2, cache = forward(X, parameters) # A2 = Y_hat\n",
    "\n",
    "A2 = np.array([[0.9999],\n",
    "               [0.0001],\n",
    "               [0.0001],\n",
    "               [0.9999]]).T\n",
    "\n",
    "'''\n",
    "Y = np.array([[1.0],\n",
    "              [0.0],\n",
    "              [0.0],\n",
    "              [1.0]]).T\n",
    "'''\n",
    "\n",
    "# BCE를 0.0으로 만들 수 있는가?\n",
    "print(\"cost = \" + str(compute_cost(A2, Y, parameters)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dW1 = $\\dfrac{\\partial J(w) }{ \\partial W_1 }$, db1 = $\\dfrac{\\partial J(w) }{ \\partial b_1 }$ , dW2 = $\\dfrac{\\partial J(w) }{ \\partial W_2 }$, db2 = $\\dfrac{\\partial J(w) }{ \\partial b_2 }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(parameters, cache, X, Y):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    grads -- python dictionary containing your gradients with respect to different parameters\n",
    "    \"\"\"\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # First, retrieve W1 and W2 from the dictionary \"parameters\".\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "        \n",
    "    # Retrieve also A1, Z1 and A2 from dictionary \"cache\".\n",
    "    A1 = cache['A1']\n",
    "    Z1 = cache['Z1']\n",
    "    A2 = cache['A2']\n",
    "    \n",
    "    # Backward propagation: calculate dW1, db1, dW2, db2. \n",
    "    # corresponding to 7 equations on slide above)\n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "# A2, cache = forward(X, parameters) # A2 = Y_hat\n",
    "\n",
    "# Your Code ...\n",
    " \n",
    "# Your Code ...\n",
    "\n",
    "print (\"dW1 = \"+ str(grads[\"dW1\"]))\n",
    "print (\"db1 = \"+ str(grads[\"db1\"]))\n",
    "print (\"dW2 = \"+ str(grads[\"dW2\"]))\n",
    "print (\"db2 = \"+ str(grads[\"db2\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " $ \\theta = \\theta - \\alpha \\dfrac{\\partial J(w) }{ \\partial \\theta }$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate=0.01):\n",
    "    \"\"\"    \n",
    "    Returns:\n",
    "    parameters -- python dictionary containing your updated parameters \n",
    "    \"\"\"\n",
    "    # Retrieve each parameter from the dictionary \"parameters\"\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "# A2, cache = forward(X, parameters) # A2 = Y_hat\n",
    "# grads = backward(parameters, cache, X, Y)\n",
    "\n",
    "# Your Code ...\n",
    " \n",
    "# Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n_x, n_h, n_y = layer_sizes(X, Y)\n",
    "# parameters = initialize_parameters(n_x, n_h, n_y)\n",
    "# A2, cache = forward(X, parameters) # A2 = Y_hat\n",
    "# compute_cost(A2, Y, parameters)\n",
    "# grads = backward(parameters, cache, X, Y)\n",
    "# parameters = update_parameters(parameters, grads, learning_rate=1.02) # Where are we wrong ?\n",
    "\n",
    "def NN_2L(X, Y, n_h, num_iterations=10000, init_scale_factor=1.0, learning_rate=0.01, print_cost=False):\n",
    "\n",
    "    np.random.seed(3)\n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[2]\n",
    "    \n",
    "    # Initialize parameters, then retrieve W1, b1, W2, b2. Inputs: \"n_x, n_h, n_y\". Outputs = \"W1, b1, W2, b2, parameters\".\n",
    "    # Your Code ...\n",
    " \n",
    "    # Your Code ...\n",
    "\n",
    "    # Epochs ...\n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        # Your Code ...\n",
    " \n",
    "        # Your Code ...\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        # Your Code ...\n",
    " \n",
    "        # Your Code ...\n",
    " \n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        # Your Code ...\n",
    " \n",
    "        # Your Code ...\n",
    "\n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        # Your Code ...\n",
    " \n",
    "        # Your Code ...\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration [%i/%i]: %f\" % (i, num_iterations, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XOR inputs & Corresponding outputs\n",
    "X_train = np.array([[0, 0], [0, 1], [1, 0], [1, 1]]).T\n",
    "Y_train = np.array([[0, 1, 1, 0]])\n",
    "\n",
    "# Your Code ...\n",
    " \n",
    "# Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    # Your Code ...\n",
    " \n",
    " \n",
    "    # Your Code ...\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predict(parameters, X_train)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy 계산\n",
    "def get_accuracy(A2, Y):\n",
    "    # Your Code ...\n",
    "  \n",
    " \n",
    "    # Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy : {:.2%}'.format(get_accuracy(predictions, Y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "def load_dataset():\n",
    "    train_dataset = h5py.File('data/train_catvnoncat.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # your train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # your train set labels\n",
    "\n",
    "    test_dataset = h5py.File('data/test_catvnoncat.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # your test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # your test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # the list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig.reshape(-1), test_set_x_orig, test_set_y_orig.reshape(-1), classes\n",
    "\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_dataset()\n",
    "X_train_flatten = X_train_orig.reshape(X_train_orig.shape[0], -1).T\n",
    "X_test_flatten = X_test_orig.reshape(X_test_orig.shape[0], -1).T\n",
    "X_train = X_train_flatten / 255.\n",
    "X_test = X_test_flatten / 255.\n",
    "Y_train = Y_train_orig.reshape(1, -1)\n",
    "Y_test = Y_test_orig.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rndsuff = np.random.randint(0, len(X_train_orig)-1, size=len(X_train_orig), dtype='l')\n",
    "\n",
    "# Sow images and labels\n",
    "plt.figure(figsize=(16,16))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_train_orig[rndsuff[i]], cmap=plt.cm.binary)\n",
    "    plt.xlabel(Y_train_orig[rndsuff[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_orig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your Code ... (Challenge)\n",
    "parameters = NN_2L(X_train, Y_train, n_h=10, num_iterations=10000, init_scale_factor=0.01, learning_rate=0.0075, print_cost=True)\n",
    "# Your Code ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report ...\n",
    "predictions = predict(parameters, X_test)\n",
    "wrong_idx = Y_test != predictions\n",
    "print('Test acc : {:.2%}'.format(get_accuracy(predictions, Y_test)))\n",
    "print(\"틀린갯수 : \"+ str(len(predictions[wrong_idx])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show images and labels\n",
    "plt.figure(figsize=(10,12))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(X_test_orig[wrong_idx[0]][i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(\"Label:\" + str(Y_test[wrong_idx][i])+\"\\n Predict:\"+str(predictions[wrong_idx][i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
